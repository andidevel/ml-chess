\input{preamble.tex}

\begin{document}

\input{frontpage.tex}

%%%%% Documento começa aqui %%%%%%%%%%%%%%%%%%%

\section{Rede Convolucional para Reconhecimento de Peças de
Xadrez}\label{rede-convolucional}

    \subsection{Breve Introdução à Redes
Convolucionais:}\label{breve-introducao-a-redes-convolucionais}

Redes convolucionais diferem por não possuirem suas camadas convolucionais totalmente
conectadas, vide a figura \ref{fig:conv-net}, e são comumente usadas quando os dados de entrada
representam imagens.

\begin{figure}[ht]
\centering
\includegraphics{tikz44.png}
\caption{Redes Convolucionais}\label{fig:conv-net}
\end{figure}

Isto torna particularmente interessante seu uso para imagens. Onde as
unidades de entradas são representadas pela intensidade dos pixels, e
no caso de imagens coloridas são acrescidas outras dimensões às
unidades de entrada.

Os pesos que mapeiam as unidades de entrada para as de saída são
matrizes que são chamadas de filtros, máscaras ou kernels. É possível
modificar alguns parâmetros das camadas como o \emph{stride}, passo que
o filtro dá ao fazer o mapeamento, o \emph{padding}, preenchimento que
aumenta o tamanho das bordas da camada de entrada com 0's e 1's. Além
disso é possível ter um filtro com mais de uma dimensão. Através desses
parâmetros é possível definir qual será o tamanho da camada de saída.

\begin{figure}[ht]
\centering
\includegraphics{tikz46.png}
\caption{Os filtros em uma rede convolucional}\label{fig:conv-net-filters}
\end{figure}

        \subsection{Batch Normalization}\label{batch-normalization}

\textbf{Batch Normalization}[4] é uma técnica de normalização de atributos que atua
entre as camadas convolucionais. A idéia é fazer com que as entradas de qualquer
camada tenha média zero e variância unitária.

\begin{figure}[ht]
\centering
\includegraphics{batch_normalization_algorithm.png}
\caption{Algoritmo do Batch Normalization}\label{fig:batch-norm}
\end{figure}


A técnica de \textbf{Batch Normalization} permite que cada camada possa aprender
um pouco mais, por si mesma, independentemente das outras camadas.

    \section{Arquitetura Inicial}\label{arquitetura-inicial}

O projeto foi fortemente baseado no tutorial disponível em
\href{http://adventuresinmachinelearning.com/keras-tutorial-cnn-11-lines/}{[1]} sobre \textbf{Redes
Convolucionais} utilizando o \href{https://keras.io/}{keras}, e, portanto, inicialmente a
arquitetura utilizada foi a mesma sugerida no post, conforme a figura \ref{fig:arch-init}.

\begin{figure}[ht]
\centering
\includegraphics{arch-01.png}
\caption{Arquitetura Inicial}\label{fig:arch-init}
\end{figure}


    \subsection{Projeto}\label{projeto}

O nosso projeto consistiu em fazer um sistema de reconhecimento de peças
de xadres baseado em imagens já segmentadas. Dessa maneira utilizamos o
conjunto de dados (imagens) disponível em [5].

Para fazer o projeto cogitamos inicialmente implementar o código na
biblioteca Tensorflow, porém por comodidade decidimos implementar na
biblioteca Keras por ser muito mais prático e intuitivo.

    \subsubsection{Dataset}\label{dataset}

O primeiro passo foi fazer o download do arquivo \emph{"Chess ID Public Data.zip"},
disponível em [5], que consiste, após descompactado, em duas pastas, \textbf{output\_test}
e \textbf{output\_train}, cada uma contendo amostras, em imagens \emph{JPEG} de 227x227 pixels,
em \textbf{RGB}, de todas as peças do xadrez (inclusive os espaços em branco do tabuleiro),
separadas por pastas, uma pasta para cada peça, por exemplo, uma pasta chamada \textbf{bb}
contendo só imagens da peça bispo preto (\textbf{black bishop}), uma pasta chamada
\textbf{wb} contendo só imagens da peça bispo branco (\textbf{white bishop}), e assim por diante.

Verificamos, que, na pasta \textbf{output\_train} haviam \textbf{10.360} amostras, enquanto que
na pasta \textbf{output\_test} haviam \textbf{185} amostras. Então resolvemos fazer
um \textbf{data augmentation} no dataset de testes fazendo uma rotação nas imagens
em 90, 180 e 270 graus, quadruplicando o número de amostras, que passou para \textbf{740}
amostras, além de converter as imagens \textbf{RGB} para \textbf{grayscale}, já que,
pelo menos no xadrez oficial, as peças só podem ser pretas ou brancas. Para isso
foi elaborado um script Python, disponível em [6], utilizando a biblioteca \textbf{OpenCV}[7].

Para facilitar a utilização, todo o conjunto de dados foi convertido para um arquivo
no formato \textbf{HDF5}[8], em 4 (quatro) \textbf{datasets} distintos:

\begin{itemize}
    \item \textbf{chess\_imgs\_train}: matriz de shape (10360, 227, 227), com todas
    as imagens de treinamento em grayscale.
    \item \textbf{chess\_labels\_train}: matriz de shape (10360, 1), indicando a
    classe de cada amostra de treinamento.
    \item \textbf{chess\_imgs\_test}: matriz de shape (740, 227, 227), com todas as
    imagens de teste em grayscale.
    \item \textbf{chess\_labels\_test}: matriz de shape (740, 1), indicando a classe
    de cada amostra de teste.
\end{itemize}

    \subsubsection{Arquitetura da Rede}

Com o conjunto de dados preparado, já poderiamos começar o treinamento, o problema
que nos deparamos foi o de que não possuíamos GPU e como o conjunto de dados era muito
grande o tempo estimado para treinamento estava em mais de 30 horas.
Após uma pesquisa resolvemos utilizar o \textbf{Google Colab}[3] e seu
serviço de utilização de GPU remota, o que reduziu o tempo de
treinamento para \textbf{10 minutos} utilizando a mesma arquitetura
inicial.

A rede que usamos não teve um resultado tão bom inicialmente, atingindo uma
acurácia de aproximadamente \textbf{26\%}, então tomamos a decisão de tornar a
rede mais profunda. Feito isso a rede teve uma melhora significativa.
Finalmente tentamos diversas técnicas diferentes com o intuito de ter um aumento
significativo, onde observamos aumentos pequenos na performance com algumas
técnicas bem sucedidas e outras técnicas resultaram em uma piora considerável.

O melhor desempenho se deu ao incluirmos o \textbf{Batch Normalization} entre as
camadas, entretanto não podíamos dizer que a melhora do desempenho foi devido a
introdução do \textbf{Batch Normalization} pois não estávamos
\emph{"normalizando"} a geração dos números aleatórios, de forma que a
melhora pode ter sido proviniente de uma inicialização da rede com pesos
melhores.

Para termos uma certa garantia que a melhora do desempenho era devido as
modificações na arquitetura da rede, bem como introdução de regularização,
etc, adicionamos o seguinte código:

\begin{lstlisting}[language=Python]
# Algumas configurações para obter "resultados reproduzíveis"
np.random.seed(42)
rn.seed(54321)
session_config = tf.ConfigProto(
    intra_op_parallelism_threads=1,
    inter_op_parallelism_threads=1
)
tf.set_random_seed(1234)
sess = tf.Session(graph=tf.get_default_graph(), config=session_config)
keras.backend.set_session(sess)
\end{lstlisting}

Assim, com a melhor acurácia em torno de \textbf{69\%}, a solução
foi, a partir da arquitetura inicial, aprofundar a rede em mais camadas,
adicionando o \textbf{Batch Normalization} entre as camadas, de forma
que a arquitetura final ficou com 5 camadas \textbf{convolucionais} +
\textbf{max pooling} + \textbf{batch normalization} + 1 camada
\textbf{fully connected} com saída \textbf{softmax}, conforme a figura \ref{fig:arch-final}.
No treinamento iniciamos com 10 épocas, mas vimos que ao aumentar o número de épocas, o
desempenho melhorava, mas como isso também aumentava o tempo de treinamento, deixamos
o treinamento com 20 épocas na fase final.

\begin{figure}[ht]
\centering
\includegraphics{arch-final.png}
\caption{Arquitetura final, com Batch Normalization nas camadas convulucionais}\label{fig:arch-final}
\end{figure}

    \subsection{Resultados:}\label{resultados}

Utilizando a arquitetura inicial, mas adicionando mais camadas, rodando 10 épocas,
obtivemos uma acurácia de \textbf{50\%}. O termo \emph{camada}, neste caso, significa
o conjunto \textbf{camada convolucional} + \textbf{max pooling}.

\begin{figure}[ht]
\centering
\includegraphics{acc-01.png}
\caption{5 camadas com 10 épocas, 50\% de acurácia}\label{fig:acc10}
\end{figure}

Após alguma modificações na rede e introduzindo \textbf{Batch Normalization}, a acurácia subiu para
\textbf{68\%}, conforme visto na figura \ref{fig:acc68}.

\begin{figure}[ht]
\centering
\includegraphics{acc-02-batch_n.png}
\caption{5 camadas, 10 épocas, adicionado o Batch Normalization}\label{fig:acc68}
\end{figure}

Assim, após mais alguns testes, aumentando o número de épocas para 20,
chegamos a uma acurácia de \textbf{69,46\%}, vide figura \ref{fig:acc69}.

\begin{figure}[H]
\centering
\includegraphics{acc6946-padding_same.png}
\caption{Arquitetura Final, 5 camadas, com Batch Normalization, 20 épocas, 69,46\% de acurácia}\label{fig:acc69}
\end{figure}

    \subsection{Conclusão:}\label{conclusao}

Durante o processo de adequação da rede, percebemos que, enquanto não \emph{"normalizamos"}
a geração dos números aleatórios, estava bem complicado construir uma arquitetura
que fosse satisfatória, pois ao treinar a mesma arquitetura mais de uma vez, obtínhamos
resultados bem diferentes, então, esse foi um passo importante no projeto para que
pudéssemos obter resultados mais consistentes e que refletiam as modificações que
estávamos fazendo na arquitetura da rede.

Também podemos comprovar que quanto mais profunda a rede, quanto mais camadas convolutivas
são acrescentadas à rede, isso reflete de maneira significativa no desempenho da mesma,
assim como aumenta significativamente o tempo de processamento.

Ainda há espaço para melhoramentos no projeto, como a inclusão de \emph{"Regularização"}, pois
percebemos que com o passar das \emph{épocas}, a rede vai aprendendo muito bem o conjunto
de treinamento mas não tem o mesmo desempenho suave no conjunto de testes.

    % Add a bibliography block to the postdoc

    \section{Referências:}\label{referencias}

[1] Tutorial Redes Convolucionais utilizando
Keras:
\href{http://adventuresinmachinelearning.com/keras-tutorial-cnn-11-lines/}{
http://adventuresinmachinelearning.com/keras-tutorial-cnn-11-lines/}\\

[2] Neural Networks and Deep Learning, Michael Nielsen:
\href{http://neuralnetworksanddeeplearning.com/}{http://neuralnetworksanddeeplearning.com/}\\

[3] Google Colab:
\href{https://colab.research.google.com}{https://colab.research.google.com}\\

[4] Ioffe, Sergey and Christian Szegedy. “Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.” ICML (2015).\\

[5] Conjunto imagens segmentadas de peças de xadrez:
\href{https://www.dropbox.com/s/618l4ddoykotmru/Chess\%20ID\%20Public\%20Data.zip?dl=0}{
https://www.dropbox.com/s/618l4ddoykotmru/Chess ID Public Data.zip?dl=0}\\

[6] EEL7513 class project:
\href{https://github.com/andidevel/ml-chess}{https://github.com/andidevel/ml-chess}\\

[7] OpenCV (Open Source Computer Vision Library):
\href{https://opencv.org/}{https://opencv.org/}\\

[8] Hierarchical Data Format:
\href{https://en.wikipedia.org/wiki/Hierarchical_Data_Format}{https://en.wikipedia.org/wiki/Hierarchical\_Data\_Format}\\

    \end{document}
